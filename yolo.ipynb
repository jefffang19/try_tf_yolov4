{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "document:\n",
    "\n",
    "https://wiki.loliot.net/docs/lang/python/libraries/yolov4/python-yolov4-about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install yolov4\n",
    "# require tensorflow 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.4.0.46-cp37-cp37m-manylinux2014_x86_64.whl (49.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 49.5 MB 259 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /home/jeff/anaconda3/envs/tf-gpu/lib/python3.7/site-packages (from opencv-python) (1.19.1)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.4.0.46\n"
     ]
    }
   ],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolov4.tf import YOLOv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class YOLOv4 in module yolov4.tf:\n",
      "\n",
      "class YOLOv4(yolov4.common.base_class.BaseClass)\n",
      " |  YOLOv4(tiny: bool = False, tpu: bool = False)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      YOLOv4\n",
      " |      yolov4.common.base_class.BaseClass\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, tiny: bool = False, tpu: bool = False)\n",
      " |      Default configuration\n",
      " |  \n",
      " |  compile(self, loss_iou_type: str = 'ciou', loss_verbose=1, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7ff6c907a350>, **kwargs)\n",
      " |  \n",
      " |  fit(self, data_set, epochs, verbose=2, callbacks=None, validation_data=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, **kwargs)\n",
      " |  \n",
      " |  load_dataset(self, dataset_path, dataset_type='converted_coco', label_smoothing=0.1, image_path_prefix=None, training=True)\n",
      " |  \n",
      " |  load_weights(self, weights_path: str, weights_type: str = 'tf')\n",
      " |      Usage:\n",
      " |          yolo.load_weights(\"yolov4.weights\", weights_type=\"yolo\")\n",
      " |          yolo.load_weights(\"checkpoints\")\n",
      " |  \n",
      " |  make_model(self, activation0: str = 'mish', activation1: str = 'leaky', kernel_regularizer=<tensorflow.python.keras.regularizers.L2 object at 0x7ff7000c6ed0>)\n",
      " |  \n",
      " |  predict(self, frame: numpy.ndarray, iou_threshold: float = 0.3, score_threshold: float = 0.25)\n",
      " |      Predict one frame\n",
      " |      \n",
      " |      @param frame: Dim(height, width, channels)\n",
      " |      \n",
      " |      @return pred_bboxes == Dim(-1, (x, y, w, h, class_id, probability))\n",
      " |  \n",
      " |  save_as_tflite(self, tflite_path, quantization=None, data_set=None, num_calibration_steps: int = 100)\n",
      " |      Save model and weights as tflite\n",
      " |      \n",
      " |      Usage:\n",
      " |          yolo.save_as_tflite(\"yolov4.tflite\")\n",
      " |          yolo.save_as_tflite(\"yolov4-float16.tflite\", \"float16\")\n",
      " |          yolo.save_as_tflite(\"yolov4-int.tflite\", \"int\", data_set)\n",
      " |  \n",
      " |  save_dataset_for_mAP(self, mAP_path, data_set, num_sample=None, images_optional=False)\n",
      " |      gt: name left top right bottom\n",
      " |      dr: name confidence left top right bottom\n",
      " |      \n",
      " |      @param `mAP_path`\n",
      " |      @parma `data_set`\n",
      " |      @param `num_sample`: Number of images for mAP. If `None`, all images in\n",
      " |              `data_set` are used.\n",
      " |      @parma `images_optional`: If `True`, images are copied to the\n",
      " |              `mAP_path`.\n",
      " |  \n",
      " |  save_weights(self, weights_path: str, weights_type: str = 'tf')\n",
      " |      Usage:\n",
      " |          yolo.save_weights(\"yolov4.weights\", weights_type=\"yolo\")\n",
      " |          yolo.save_weights(\"checkpoints\")\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from yolov4.common.base_class.BaseClass:\n",
      " |  \n",
      " |  candidates_to_pred_bboxes(self, candidates, iou_threshold: float = 0.3, score_threshold: float = 0.25)\n",
      " |      @param candidates: Dim(-1, (x, y, w, h, conf, prob_0, prob_1, ...))\n",
      " |      \n",
      " |      @return Dim(-1, (x, y, w, h, class_id, probability))\n",
      " |  \n",
      " |  draw_bboxes(self, image, bboxes)\n",
      " |      @parma image:  Dim(height, width, channel)\n",
      " |      @param bboxes: (candidates, 4) or (candidates, 5)\n",
      " |              [[center_x, center_y, w, h, class_id], ...]\n",
      " |              [[center_x, center_y, w, h, class_id, propability], ...]\n",
      " |      \n",
      " |      @return drawn_image\n",
      " |      \n",
      " |      Usage:\n",
      " |          image = yolo.draw_bboxes(image, bboxes)\n",
      " |  \n",
      " |  fit_pred_bboxes_to_original(self, pred_bboxes, original_shape)\n",
      " |      @param pred_bboxes:    Dim(-1, (x, y, w, h, class_id, probability))\n",
      " |      @param original_shape: (height, width, channels)\n",
      " |  \n",
      " |  inference(self, media_path, is_image: bool = True, cv_apiPreference=None, cv_frame_size: tuple = None, cv_fourcc: str = None, cv_waitKey_delay: int = 1, iou_threshold: float = 0.3, score_threshold: float = 0.25)\n",
      " |  \n",
      " |  resize_image(self, image, ground_truth=None)\n",
      " |      @param image:        Dim(height, width, channels)\n",
      " |      @param ground_truth: [[center_x, center_y, w, h, class_id], ...]\n",
      " |      \n",
      " |      @return resized_image or (resized_image, resized_ground_truth)\n",
      " |      \n",
      " |      Usage:\n",
      " |          image = yolo.resize_image(image)\n",
      " |          image, ground_truth = yolo.resize_image(image, ground_truth)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from yolov4.common.base_class.BaseClass:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  anchors\n",
      " |      Usage:\n",
      " |          yolo.anchors = [12, 16, 19, 36, 40, 28, 36, 75,\n",
      " |                          76, 55, 72, 146, 142, 110, 192, 243, 459, 401]\n",
      " |          yolo.anchors = np.array([12, 16, 19, 36, 40, 28, 36, 75,\n",
      " |                          76, 55, 72, 146, 142, 110, 192, 243, 459, 401])\n",
      " |          print(yolo.anchors)\n",
      " |  \n",
      " |  classes\n",
      " |      Usage:\n",
      " |          yolo.classes = {0: 'person', 1: 'bicycle', 2: 'car', ...}\n",
      " |          yolo.classes = \"path/classes\"\n",
      " |          print(len(yolo.classes))\n",
      " |  \n",
      " |  input_size\n",
      " |      (width, height)\n",
      " |      \n",
      " |      Usage:\n",
      " |          yolo.input_size = 608\n",
      " |          yolo.input_size = (608, 416) # (width, height)\n",
      " |          print(yolo.input_size)\n",
      " |  \n",
      " |  strides\n",
      " |      Tiny(convolution stride = 2)\n",
      " |          640x480 -> 320x240 -> ... -> 40x30 -> ... -> 20x15 -> ... -> 40x30\n",
      " |          pred_m: 640x480 -> stride = 16 -> 40x30\n",
      " |          pred_l: 640x480 -> stride = 32 -> 20x15\n",
      " |  \n",
      " |  xyscales\n",
      " |      Usage:\n",
      " |          yolo.xyscales = [1.2, 1.1, 1.05]\n",
      " |          yolo.xyscales = np.array([1.2, 1.1, 1.05])\n",
      " |          print(yolo.xyscales)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(YOLOv4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1974.14 ms\n",
      "YOLOv4: Inference is finished\n"
     ]
    }
   ],
   "source": [
    "from yolov4.tf import YOLOv4\n",
    "\n",
    "yolo = YOLOv4()\n",
    "# yolo = YOLOv4(tiny=True)\n",
    "\n",
    "yolo.classes = \"coco.names\"\n",
    "yolo.input_size = (640, 480)\n",
    "\n",
    "yolo.make_model()\n",
    "yolo.load_weights(\"yolov4.weights\", weights_type=\"yolo\")\n",
    "# yolo.load_weights(\"yolov4-tiny.weights\", weights_type=\"yolo\")\n",
    "\n",
    "yolo.inference(media_path= \"dog.jpg\")\n",
    "\n",
    "# yolo.inference(media_path=\"road.mp4\", is_image=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
